{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = '/home/dipp/Github/Master-Thesis-dipp/Extracting_Locations_that_has_Value/Trimming_Further/test_data_v2.csv'\n",
    "res_Data = '/home/dipp/Github/Master-Thesis-dipp/Extracting_Locations_that_has_Value/Trimming_Further/res_data_v2.csv'\n",
    "\n",
    "cols = ['i','j','count']\n",
    "res_dict = {}\n",
    "No_of_rows_in_original = 0\n",
    "No_of_rows_after_count = 0\n",
    "No_of_None = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Here\n",
      "Calculations Done: No of Rows:  498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8818/3293890190.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(loc_data, sep='],', names=cols)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(loc_data, sep='],', names=cols)\n",
    "print(\"Done Here\")\n",
    "df = df.drop(index=0)\n",
    "df = df.dropna()\n",
    "#print(\"Now Enterted Here\")\n",
    "#new_df = pd.DataFrame(columns=cols)\n",
    "#print(\"Now created new DF\")\n",
    "No_of_rows_in_original = len(df)\n",
    "print(\"Calculations Done: No of Rows: \", No_of_rows_in_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i         object\n",
      "j         object\n",
      "count    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['count'].astype('Int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>['US', 'United States', 'NY', 'New York', 'New...</td>\n",
       "      <td>['US', 'United States', 'ID', 'Idaho', Coeur d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     i  \\\n",
       "421  ['US', 'United States', 'NY', 'New York', 'New...   \n",
       "\n",
       "                                                     j  count  \n",
       "421  ['US', 'United States', 'ID', 'Idaho', Coeur d...    NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5      False\n",
       "       ...  \n",
       "495    False\n",
       "496    False\n",
       "497    False\n",
       "498    False\n",
       "499    False\n",
       "Name: count, Length: 499, dtype: bool"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['count'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          47.0\n",
       "2       19579.0\n",
       "3      126208.0\n",
       "4           2.0\n",
       "5       37724.0\n",
       "         ...   \n",
       "495         4.0\n",
       "496       163.0\n",
       "497         4.0\n",
       "498       115.0\n",
       "499      7913.0\n",
       "Name: count, Length: 499, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### DF TO DICT DONE #########################\n"
     ]
    }
   ],
   "source": [
    "loc_reader = {}\n",
    "loc_reader = df.to_dict('index')\n",
    "\n",
    "print('############### DF TO DICT DONE #########################')\n",
    "for index, line in loc_reader.items():\n",
    "        \n",
    "        #No_of_rows_in_original += 1\n",
    "        a = (line['i'].replace('[','')).split()\n",
    "        b = (line['j'].replace('[','')).split()\n",
    "        #c = int(line['count'].replace(',',''))\n",
    "        c = float(line['count'])\n",
    "        #c = line['count'].replace(',','')\n",
    "        temp_i = a[0].replace(',','')\n",
    "        temp_j = b[0].replace(',','')\n",
    "        temp_count = c\n",
    "\n",
    "        temp_lookup_data = temp_i + '+' + temp_j\n",
    "        temp_lookup = res_dict.get(temp_lookup_data)\n",
    "\n",
    "        if(temp_lookup == None):\n",
    "            res_dict[temp_lookup_data] = temp_count\n",
    "        else:\n",
    "            res_dict[temp_lookup_data] = temp_count + temp_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'CA'+'CA'\": 161904.0,\n",
       " \"'US'+'RU'\": 19579.0,\n",
       " \"'US'+'US'\": 6169466.0,\n",
       " \"'GB'+'MY'\": 4777.0,\n",
       " \"'IN'+'IN'\": 3310821.0,\n",
       " \"'KR'+'US'\": 30442.0,\n",
       " \"'BE'+'US'\": 25.0,\n",
       " \"'ES'+'ES'\": 6339.0,\n",
       " \"'AU'+'AU'\": 69152.0,\n",
       " \"'MX'+'MX'\": 16836.0,\n",
       " \"'BE'+'BE'\": 42699.0,\n",
       " \"'GB'+'MX'\": 264.0,\n",
       " \"'US'+'DE'\": 315.0,\n",
       " \"'IT'+'IT'\": 9625.0,\n",
       " \"'US'+'IT'\": 2025.0,\n",
       " \"'AR'+'AR'\": 11706.0,\n",
       " \"'US'+'PA'\": 63.0,\n",
       " \"'DE'+'DE'\": 68377.0,\n",
       " \"'GB'+'GB'\": 1550918.0,\n",
       " \"'US'+'HK'\": 3377.0,\n",
       " \"'US'+'TH'\": 3789.0,\n",
       " \"'US'+'CA'\": 5112.0,\n",
       " \"'PH'+'MY'\": 253.0,\n",
       " \"'CU'+'IN'\": 4609.0,\n",
       " \"'US'+'GB'\": 17711.0,\n",
       " \"'PH'+'PH'\": 6461.0,\n",
       " \"'US'+'MY'\": 2028.0,\n",
       " \"'JP'+'JP'\": 736.0,\n",
       " \"'VE'+'VE'\": 42261.0,\n",
       " \"'IN'+'US'\": 215676.0,\n",
       " \"'GB'+'US'\": 90357.0,\n",
       " \"'TR'+'TR'\": 156252.0,\n",
       " \"'GR'+'GR'\": 1263.0,\n",
       " \"'AG'+'AG'\": 2081.0,\n",
       " \"'US'+'CO'\": 117.0,\n",
       " \"'ZA'+'ZA'\": 449632.0,\n",
       " \"'MC'+'MC'\": 5873.0,\n",
       " \"'LB'+'GB'\": 2.0,\n",
       " \"'AU'+'PL'\": 8.0,\n",
       " \"'MX'+'CO'\": 101.0,\n",
       " \"'TH'+'TH'\": 47227.0,\n",
       " \"'PA'+'PA'\": 47971.0,\n",
       " \"'US'+'ZA'\": 3398.0,\n",
       " \"'KE'+'KE'\": 158278.0,\n",
       " \"'DE'+'TR'\": 1021.0,\n",
       " \"'CO'+'CO'\": 1318832.0,\n",
       " \"'US'+'AT'\": 211.0,\n",
       " \"'IN'+'SA'\": 3634.0,\n",
       " \"'SA'+'SA'\": 25247.0,\n",
       " \"'RU'+'CA'\": 253.0,\n",
       " \"'CU'+'CU'\": 447865.0,\n",
       " \"'ZA'+'DE'\": 140.0,\n",
       " \"'US'+'IN'\": 75611.0,\n",
       " \"'NL'+'NL'\": 118.0,\n",
       " \"'GB'+'FR'\": 579.0,\n",
       " \"'US'+'KE'\": 11282.0,\n",
       " \"'US'+'TR'\": 5522.0,\n",
       " \"'PK'+'PK'\": 17588.0,\n",
       " \"'US'+'AU'\": 24391.0,\n",
       " \"'TH'+'US'\": 530.0,\n",
       " \"'US'+'NG'\": 2066.0,\n",
       " \"'HK'+'US'\": 10908.0,\n",
       " \"'NG'+'US'\": 61.0,\n",
       " \"'GB'+'CO'\": 3113.0,\n",
       " \"'BE'+'GB'\": 79.0,\n",
       " \"'MY'+'MY'\": 46513.0,\n",
       " \"'US'+'JP'\": 6810.0,\n",
       " \"'GB'+'IT'\": 87.0,\n",
       " \"'NL'+'US'\": 6.0,\n",
       " \"'NZ'+'GB'\": 115.0,\n",
       " \"'GB'+'IN'\": 20959.0,\n",
       " \"'EG'+'IT'\": 7.0,\n",
       " \"'SE'+'US'\": 5.0,\n",
       " \"'IQ'+'IQ'\": 9115.0,\n",
       " \"'US'+'SA'\": 101.0,\n",
       " \"'SE'+'SE'\": 1536.0,\n",
       " \"'AU'+'US'\": 12.0,\n",
       " \"'IN'+'PK'\": 1414.0,\n",
       " \"'JP'+'US'\": 633.0,\n",
       " \"'CO'+'ES'\": 85.0,\n",
       " \"'HK'+'HK'\": 249610.0,\n",
       " \"'GB'+'JP'\": 1764.0,\n",
       " \"'US'+'CM'\": 328.0,\n",
       " \"'CL'+'CL'\": 1011.0,\n",
       " \"'AU'+'FR'\": 1.0,\n",
       " \"'US'+'SG'\": 837.0,\n",
       " \"'US'+'ZW'\": 2404.0,\n",
       " \"'CO'+'US'\": 2430.0,\n",
       " \"'DE'+'US'\": 12.0,\n",
       " \"'ID'+'ID'\": 9194.0,\n",
       " \"'ID'+'US'\": 25.0,\n",
       " \"'FR'+'NG'\": 110.0,\n",
       " \"'NZ'+'NZ'\": 75.0,\n",
       " \"'US'+'NO'\": 4.0,\n",
       " \"'IN'+'GB'\": 31364.0,\n",
       " \"'PG'+'PG'\": 3062.0,\n",
       " \"'NG'+'NG'\": 276603.0,\n",
       " \"'US'+'IL'\": 1088.0,\n",
       " \"'ZA'+'ZW'\": 2.0,\n",
       " \"'US'+'MX'\": 898.0,\n",
       " \"'MX'+'US'\": 115.0}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ LOCATION DICT MADE #####################\n",
      "########## WRITING TO FILE ###########\n",
      "####### RESULTS WRITTEN TO FILE ###########\n"
     ]
    }
   ],
   "source": [
    "print(\"################ LOCATION DICT MADE #####################\")\n",
    "\n",
    "file1 = open(res_Data, \"a\")  # append mode\n",
    "file1.write('i,j,count'+'\\n')\n",
    "file1.close()\n",
    "\n",
    "No_of_rows_after_count = 0\n",
    "\n",
    "print(\"########## WRITING TO FILE ###########\")\n",
    "for a,b in res_dict.items():\n",
    "    temp = a.split('+')\n",
    "    source_i = temp[0]\n",
    "    destination_j = temp[1]\n",
    "    count = b\n",
    "    file1 = open(res_Data, \"a\")\n",
    "    file1.writelines(str(source_i) + ',' + str(destination_j) + ',' + str(count) + '\\n')\n",
    "    file1.flush()\n",
    "    No_of_rows_after_count += 1\n",
    "\n",
    "file1.close()\n",
    "print(\"####### RESULTS WRITTEN TO FILE ###########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "loc_data = '/home/dipp/Github/Master-Thesis-dipp/Extracting_Locations_that_has_Value/Trimming_Further/test_data_v2.csv'\n",
    "res_Data = '/home/dipp/Github/Master-Thesis-dipp/Extracting_Locations_that_has_Value/Trimming_Further/res_data_v2.csv'\n",
    "\n",
    "cols = ['i','j','count']\n",
    "res_dict = {}\n",
    "No_of_rows_in_original = 0\n",
    "No_of_rows_after_count = 0\n",
    "No_of_None = 0\n",
    "\n",
    "print(\"############ START ################\")\n",
    "\n",
    "\n",
    "print(\"############ MAKING DataFrame #############\")\n",
    "\n",
    "#df = pd.read_csv(loc_data, sep='],', header=0, names=cols)\n",
    "\n",
    "df = pd.read_csv(loc_data, sep='],', names=cols)\n",
    "print(\"Done Here\")\n",
    "df = df.drop(index=0)\n",
    "#print(\"Now Enterted Here\")\n",
    "#new_df = pd.DataFrame(columns=cols)\n",
    "#print(\"Now created new DF\")\n",
    "No_of_rows_in_original = len(df)\n",
    "print(\"Calculations Done: No of Rows: \", No_of_rows_in_original)\n",
    "\n",
    "\n",
    "loc_reader = {}\n",
    "loc_reader = df.to_dict('index')\n",
    "\n",
    "print('############### DF TO DICT DONE #########################')\n",
    "for index, line in loc_reader.items():\n",
    "        \n",
    "        #No_of_rows_in_original += 1\n",
    "        a = (line['i'].replace('[','')).split()\n",
    "        b = (line['j'].replace('[','')).split()\n",
    "        #c = int(line['count'].replace(',',''))\n",
    "        c = line['count']\n",
    "        #c = line['count'].replace(',','')\n",
    "        temp_i = a[0].replace(',','')\n",
    "        temp_j = b[0].replace(',','')\n",
    "        temp_count = c\n",
    "\n",
    "        temp_lookup_data = temp_i + '+' + temp_j\n",
    "        temp_lookup = res_dict.get(temp_lookup_data)\n",
    "\n",
    "        if(temp_lookup == None):\n",
    "            res_dict[temp_lookup_data] = int(temp_count)\n",
    "        else:\n",
    "            res_dict[temp_lookup_data] = int(temp_count) + int(temp_lookup)\n",
    "        \n",
    "\n",
    "\n",
    "print(\"################ LOCATION DICT MADE #####################\")\n",
    "\n",
    "file1 = open(res_Data, \"a\")  # append mode\n",
    "file1.write('i,j,count'+'\\n')\n",
    "file1.close()\n",
    "\n",
    "No_of_rows_after_count = 0\n",
    "\n",
    "print(\"########## WRITING TO FILE ###########\")\n",
    "for a,b in res_dict.items():\n",
    "    temp = a.split('+')\n",
    "    source_i = temp[0]\n",
    "    destination_j = temp[1]\n",
    "    count = int(b)\n",
    "    file1 = open(res_Data, \"a\")\n",
    "    file1.writelines(str(source_i) + ',' + str(destination_j) + ',' + str(count) + '\\n')\n",
    "    file1.flush()\n",
    "    No_of_rows_after_count += 1\n",
    "\n",
    "file1.close()\n",
    "print(\"####### RESULTS WRITTEN TO FILE ###########\")\n",
    "\n",
    "#new_df.to_csv(res_Data, encoding='utf-8', index=False)\n",
    "#No_of_rows_after_count = len(new_df)\n",
    "            \n",
    "\n",
    "#print(\"######## Written to file ########\")\n",
    "\n",
    "\n",
    "print(\"No. of rows in the Original: \", No_of_rows_in_original)\n",
    "print(\"No. of rows after count: \", No_of_rows_after_count)\n",
    "#print(\"No. of None\", No_of_None)\n",
    "\n",
    "print(\"######## DONE ########\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
